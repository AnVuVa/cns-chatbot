# ğŸ¤– Enterprise Self-Learning Hybrid Chatbot

![Node.js](https://img.shields.io/badge/Node.js-v18+-green)
![Supabase](https://img.shields.io/badge/Database-Supabase%20(pgvector)-3ECF8E)
![Redis](https://img.shields.io/badge/Cache-Upstash%20Redis-red)
![AI](https://img.shields.io/badge/AI-Mistral%20%7C%20Gemini%20%7C%201min.ai-blue)
![Messenger](https://img.shields.io/badge/Channel-Facebook%20Messenger-0084FF)

Há»‡ thá»‘ng **Backend Chatbot doanh nghiá»‡p hiá»‡u nÄƒng cao**, sá»­ dá»¥ng kiáº¿n trÃºc **Hybrid RAG** (Retrieval-Augmented Generation). Há»‡ thá»‘ng káº¿t há»£p sá»©c máº¡nh tÃ¬m kiáº¿m **Vector**, bá»™ nhá»› Ä‘á»‡m **Redis** vÃ  cÆ¡ cháº¿ **Ä‘á»‹nh tuyáº¿n AI thÃ´ng minh (AI Router)** Ä‘á»ƒ tá»‘i Æ°u hÃ³a chi phÃ­ vÃ  Ä‘á»™ chÃ­nh xÃ¡c.

## ğŸŒŸ TÃ­nh nÄƒng ná»•i báº­t

* **Phá»…u lá»c 3 lá»›p (3-Layer Funnel):** Tá»‘i Æ°u tá»‘c Ä‘á»™ pháº£n há»“i vÃ  chi phÃ­.
    1.  **Layer 1 (Cache):** Pháº£n há»“i tá»©c thÃ¬ (<50ms) cho cÃ¡c cÃ¢u há»i Ä‘Ã£ Ä‘Æ°á»£c cache.
    2.  **Layer 2 (RAG Search):** TÃ¬m kiáº¿m tri thá»©c doanh nghiá»‡p vá»›i Vector similarity.
    3.  **Layer 3 (AI Generation):** LLM xá»­ lÃ½ vá»›i ngá»¯ cáº£nh tá»« RAG, cÃ³ fallback tá»± Ä‘á»™ng.

* **Multi-Provider AI Support:**
    - ğŸ†• **Mistral AI** - LLM + Embeddings
    - **Google Gemini** - LLM + Embeddings  
    - **1min.ai** - Multi-model gateway (GPT-4o, Gemini, etc.)

* **Facebook Messenger Integration:** ğŸ†•
    - Webhook verification & event handling
    - Real-time message processing
    - Typing indicators
    - Reply-to-message (quotes original question)

* **Conversation Memory:** ğŸ†•
    - 30-minute session context
    - Automatic session archiving
    - Multi-user concurrent support

* **Smart Ingestion Pipeline:** Há»— trá»£ náº¡p dá»¯ liá»‡u tá»« file `.txt`, `.pdf`, `.docx`, `.md`.

* **Customizable Bot Persona:** Prompt chuyÃªn nghiá»‡p, cÃ³ thá»ƒ tÃ¹y chá»‰nh trong `src/config/prompts.js`.

* **Comprehensive Logging System:** ğŸ†•
    - `logs/request_<date>.log` - HTTP requests
    - `logs/system_log_<date>.log` - System events + performance timing
    - `logs/llm_<date>.log` - LLM input/output

* **Real-time:** Há»— trá»£ giao tiáº¿p qua **WebSocket (Socket.io)**.

---

## ğŸ›  YÃªu cáº§u há»‡ thá»‘ng

* **Runtime:** **Node.js v18** trá»Ÿ lÃªn.
* **Database:** TÃ i khoáº£n **[Supabase](https://supabase.com)** (PostgreSQL + pgvector).
* **Cache:** TÃ i khoáº£n **[Upstash](https://upstash.com)** (Redis Serverless).
* **AI Keys:** (Ãt nháº¥t 1 provider)
    * **Mistral AI** - [console.mistral.ai](https://console.mistral.ai)
    * **Google Gemini** - [aistudio.google.com](https://aistudio.google.com/app/apikey)
    * **1min.ai** - [1min.ai/user/api](https://1min.ai/user/api)
* **Facebook App** (Optional): Cho Messenger integration.

---

## ğŸš€ CÃ i Ä‘áº·t & Khá»Ÿi cháº¡y

### 1. Clone & Install

```bash
git clone <your-repo-url>
cd cns-chatbot-api
npm install
```

### 2. Cáº¥u hÃ¬nh Environment (`.env`)

Táº¡o file `.env` tá»« template:

```bash
cp .env.example .env
```

Cáº¥u hÃ¬nh cÃ¡c biáº¿n mÃ´i trÆ°á»ng:

```env
PORT=3000

# === DATABASE ===
SUPABASE_URL=https://your-project-id.supabase.co
SUPABASE_KEY=your-anon-key-here

# === CACHE ===
UPSTASH_REDIS_REST_URL=https://your-redis-url.upstash.io
UPSTASH_REDIS_REST_TOKEN=your-redis-token-here

# === AI PROVIDERS CONFIG ===
# Choose your preferred LLM provider: 'onemin' | 'gemini' | 'mistral'
LLM_PROVIDER=mistral
LLM_FALLBACK_PROVIDER=gemini

# Choose your embedding provider: 'gemini' | 'mistral'
EMBEDDING_PROVIDER=gemini

# === MISTRAL AI ===
MISTRAL_API_KEY=your-mistral-api-key
MISTRAL_MODEL=mistral-small-latest

# === GOOGLE GEMINI ===
GEMINI_API_KEY=AIzaSy...
GEMINI_MODEL=gemini-2.5-flash

# === 1MIN.AI ===
ONEMIN_API_KEY=your-1min-api-key
ONEMIN_MODEL=gemini-2.5-flash

# === FACEBOOK MESSENGER ===
FB_PAGE_ACCESS_TOKEN=your_page_access_token
FB_VERIFY_TOKEN=my_secret_verify_token_2024
FB_APP_SECRET=your_app_secret
```

### 3. Thiáº¿t láº­p Database (Supabase SQL)

Truy cáº­p Supabase Dashboard > **SQL Editor** vÃ  cháº¡y cÃ¡c script:

**a. Core Tables:**

```sql
-- KÃ­ch hoáº¡t Vector Extension
create extension if not exists vector;

-- Báº£ng phiÃªn chat
create table chat_sessions (
  id uuid primary key default gen_random_uuid(),
  user_id varchar not null,
  metadata jsonb,
  created_at timestamptz default now()
);

-- Báº£ng tri thá»©c (Knowledge Base)
create table knowledge_base (
  id bigint generated by default as identity primary key,
  content text not null,
  embedding vector(768), -- Gemini: 768, Mistral: 1024
  source_type varchar(50),
  metadata jsonb default '{}'::jsonb,
  is_active boolean default true
);

-- Báº£ng lá»‹ch sá»­ chat (Logs)
create table chat_logs (
  id bigint generated by default as identity primary key,
  session_id uuid references chat_sessions(id),
  user_question text,
  bot_response text,
  provider varchar,
  latency_ms int,
  cost_estimated float,
  handled_by_layer int,
  processed_for_learning boolean default false,
  created_at timestamptz default now()
);

-- HÃ m tÃ¬m kiáº¿m Vector (Match Documents)
create or replace function match_documents (
  query_embedding vector(768),
  match_threshold float,
  match_count int
)
returns table (
  id bigint,
  content text,
  similarity float
)
language plpgsql
as $$
begin
  return query
  select
    knowledge_base.id,
    knowledge_base.content,
    1 - (knowledge_base.embedding <=> query_embedding) as similarity
  from knowledge_base
  where 1 - (knowledge_base.embedding <=> query_embedding) > match_threshold
  order by similarity desc
  limit match_count;
end;
$$;
```

**b. Messenger Tables (Optional):**

```sql
-- Run: scripts/messenger-schema.sql
CREATE TABLE IF NOT EXISTS messenger_logs (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    psid VARCHAR NOT NULL,
    message_type VARCHAR(20),
    message_text TEXT,
    response_text TEXT,
    latency_ms INT,
    event_type VARCHAR(50) DEFAULT 'message',
    created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX IF NOT EXISTS idx_messenger_logs_psid ON messenger_logs(psid);
CREATE INDEX IF NOT EXISTS idx_messenger_logs_created_at ON messenger_logs(created_at);
```

---

## ğŸ“š Quáº£n lÃ½ dá»¯ liá»‡u tri thá»©c (Ingestion)

**BÆ°á»›c 1:** Táº¡o thÆ° má»¥c vÃ  thÃªm tÃ i liá»‡u:

```bash
mkdir knowledge_data
# Copy cÃ¡c file .pdf, .docx, .txt, .md vÃ o thÆ° má»¥c nÃ y
```

**BÆ°á»›c 2:** Cháº¡y script náº¡p dá»¯ liá»‡u:

```bash
npm run ingest
```

> Script sáº½ tá»± Ä‘á»™ng Ä‘á»c file, cáº¯t nhá» (chunking), táº¡o vector embedding vÃ  lÆ°u vÃ o Supabase.

---

## â–¶ï¸ Cháº¡y Server

**Development** (Auto-restart):
```bash
npm run dev
```

**Production**:
```bash
npm start
```

> Server cháº¡y táº¡i: **http://localhost:3000**

---

## ğŸ”Œ API Documentation

### 1. Chat Message

```http
POST /api/chat/message
Content-Type: application/json

{
  "userId": "user_12345",
  "sessionId": "optional-session-uuid",
  "question": "Quy trÃ¬nh xin nghá»‰ phÃ©p nhÆ° tháº¿ nÃ o?"
}
```

### 2. Statistics

```http
GET /api/stats/overview      # Thá»‘ng kÃª tá»•ng quan
GET /api/stats/recent        # Lá»‹ch sá»­ chat gáº§n Ä‘Ã¢y
GET /api/stats/messenger     # Thá»‘ng kÃª Messenger
```

### 3. Messenger Webhook

```http
GET  /webhook/messenger      # Verification
POST /webhook/messenger      # Receive messages
```

### 4. WebSocket (Real-time)

```javascript
const socket = io('ws://localhost:3000');

socket.emit('join_room', sessionId);
socket.emit('send_message', { userId, sessionId, question });
socket.on('receive_message', ({ answer, timestamp }) => {});
```

---

## ğŸ“‚ Cáº¥u trÃºc dá»± Ã¡n

```plaintext
cns-chatbot-api/
â”œâ”€â”€ knowledge_data/           # TÃ i liá»‡u gá»‘c (PDF, Docx...)
â”œâ”€â”€ logs/                     # Log files (auto-generated)
â”‚   â”œâ”€â”€ request_*.log
â”‚   â”œâ”€â”€ system_log_*.log
â”‚   â””â”€â”€ llm_*.log
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ ingest-text.js        # Script náº¡p dá»¯ liá»‡u
â”‚   â”œâ”€â”€ daily-learning-job.js # Script tá»± há»c (Cron job)
â”‚   â””â”€â”€ messenger-schema.sql  # SQL cho Messenger tables
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ adapters/             # Platform adapters (Messenger)
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ env.js
â”‚   â”‚   â”œâ”€â”€ prompts.js        # ğŸ†• Centralized prompts
â”‚   â”‚   â”œâ”€â”€ redis.js
â”‚   â”‚   â””â”€â”€ supabase.js
â”‚   â”œâ”€â”€ controllers/
â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”œâ”€â”€ ai.interface.js
â”‚   â”‚   â”œâ”€â”€ gemini.provider.js
â”‚   â”‚   â”œâ”€â”€ mistral.provider.js  # ğŸ†•
â”‚   â”‚   â””â”€â”€ onemin.provider.js
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ chat.routes.js
â”‚   â”‚   â”œâ”€â”€ messenger.routes.js
â”‚   â”‚   â””â”€â”€ stats.routes.js
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ chat.service.js
â”‚   â”‚   â”œâ”€â”€ messenger.service.js
â”‚   â”‚   â””â”€â”€ rag.service.js
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ logger.js         # ğŸ†• Logging utility
â”‚   â”œâ”€â”€ app.js
â”‚   â””â”€â”€ server.js
â”œâ”€â”€ .env
â”œâ”€â”€ .env.example
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

---

## ğŸ¨ TÃ¹y chá»‰nh Bot Persona

Chá»‰nh sá»­a file `src/config/prompts.js` Ä‘á»ƒ thay Ä‘á»•i:
- Phong cÃ¡ch tráº£ lá»i (chuyÃªn nghiá»‡p/thÃ¢n thiá»‡n)
- ThÃ´ng tin liÃªn há»‡ há»— trá»£
- NguyÃªn táº¯c xá»­ lÃ½ cÃ¢u há»i
- HÃ nh vi xá»­ lÃ½ cÃ¢u há»i

---

## ğŸ“ Changelog

### v1.2.0 (2026-01-02)
- ğŸ†• **Conversation Memory** - Bot now remembers context within 30-minute sessions
- ğŸ†• **Reply-to-Message** - Messenger responses quote the original user message
- ğŸ†• **Performance Monitoring** - Detailed timing for each pipeline stage (cache, RAG, LLM)
- ğŸ†• **Conversation Archive** - Expired sessions saved to database for training
- ğŸ†• **Multi-user Support** - Concurrent conversations via in-memory Map storage

### v1.1.0 (2026-01-01)
- ğŸ†• **Facebook Messenger Integration** - Webhook, message handling
- ğŸ†• **Mistral AI Provider** - LLM + Embeddings support
- ğŸ†• **Configurable Provider Selection** - Via environment variables
- ğŸ†• **Centralized Prompts** - Easy customization in `prompts.js`
- ğŸ†• **Comprehensive Logging** - Request, system, and LLM logs
- ğŸ†• **Customizable Bot Persona** - Professional enterprise assistant

### v1.0.0
- Initial release with Gemini + 1min.ai
- RAG with Supabase pgvector
- Redis caching layer
- WebSocket real-time support
